# Issue场景分类算法说明文档

## 1. 项目概述

### 1.1 背景

本项目为Issue诊断系统提供智能场景分类功能。系统支持7种Issue场景：

| 标签 | 场景名称 | 说明 |
|-----|---------|------|
| 0 | performance | 性能问题 |
| 1 | battery life | 电池续航问题 |
| 2 | 单双烤 | 单/双烤机测试相关问题 |
| 3 | BSOD | 蓝屏死机 |
| 4 | hang | 系统挂起/卡死 |
| 5 | abnormal reboot | 异常重启 |
| 6 | abnormal shutdown | 异常关机 |

### 1.2 目标

根据用户填报的Issue信息（标题和描述），自动推测用户最可能遇到的场景，减少用户手动选择的负担，提升用户体验。

---

## 2. 算法原理

### 2.1 算法流程图

```
输入: Issue标题 + 描述
    ↓
文本预处理（jieba分词）
    ↓
TF-IDF特征提取
    ↓
机器学习分类器（逻辑回归）
    ↓
输出: 场景预测 + 置信度
```

### 2.2 技术方案

#### 2.2.1 文本预处理

**目的**：将原始文本转换为适合机器学习的格式

**混合语言处理策略**：

由于数据主要是英文，少量中文，系统采用智能语言检测和混合分词策略：

**处理步骤**：
1. 合并title和description字段
2. 检测文本中中文字符比例
3. 根据语言比例选择分词策略：
   - **纯中文（中文>50%）**：使用jieba分词
   - **英文为主或混合文本**：
     - 英文部分：nltk分词 + 转小写 + 去停用词
     - 中文部分：jieba分词
     - 智能分离并组合两种分词结果

**示例1（纯英文）**：
```
输入: "System Performance Test FAILED in benchmark"
输出: "system performance test failed benchmark"
（已去除停用词in，转小写）
```

**示例2（英文+中文混合）**：
```
输入: "PCmark8 performance score很低 during stress test"
输出: "pcmark8 performance score 很 低 stress test"
（英文部分用nltk，中文部分用jieba）
```

**示例3（纯中文）**：
```
输入: "系统性能测试失败"
输出: "系统 性能 测试 失败"
（全部用jieba分词）
```

#### 2.2.2 特征提取 - TF-IDF

**TF-IDF（Term Frequency-Inverse Document Frequency）**是一种统计方法，用于评估一个词对于一个文档的重要程度。

**核心思想**：
- **TF（词频）**：词在文档中出现的频率
- **IDF（逆文档频率）**：词在整个语料库中的稀有程度

**公式**：
```
TF-IDF = TF × IDF
```

**参数配置**：
- `max_features=5000`：最多保留5000个特征词
- `ngram_range=(1, 2)`：使用unigram（单个词）和bigram（两个词的组合）
- `min_df=2`：词至少在2个文档中出现
- `max_df=0.8`：词最多在80%的文档中出现（过滤常见词）

**优势**：
- 能够捕捉关键词的重要性
- 自动过滤停用词和常见词（英文停用词通过nltk过滤）
- 计算效率高，适合实时预测
- 支持英文和中文混合文本

#### 2.2.3 分类算法

**选择：逻辑回归（Logistic Regression）**

**选择理由**：
1. **适合小数据集**：对于594条样本的数据集，逻辑回归表现稳定
2. **训练速度快**：秒级完成训练
3. **可解释性强**：可以分析特征权重，了解哪些词对分类贡献大
4. **支持概率输出**：可以给出每个场景的置信度
5. **内存占用小**：模型文件小，便于部署

**参数配置**：
- `max_iter=1000`：最大迭代次数
- `random_state=42`：随机种子，保证可重复性
- `class_weight='balanced'`：自动平衡类别权重，处理类别不平衡问题

**其他候选算法**（在训练脚本中进行了对比）：
- 随机森林（Random Forest）
- 梯度提升树（Gradient Boosting）
- 支持向量机（SVM）

### 2.3 模型评估

#### 2.3.1 评估指标

| 指标 | 说明 | 用途 |
|-----|------|------|
| **Accuracy（准确率）** | 正确预测的样本占总样本的比例 | 整体性能评估 |
| **Precision（精确率）** | 预测为某类的样本中，实际为该类的比例 | 评估误报率 |
| **Recall（召回率）** | 实际为某类的样本中，被正确预测的比例 | 评估漏报率 |
| **F1 Score** | 精确率和召回率的调和平均 | 综合评估 |
| **Confusion Matrix（混淆矩阵）** | 展示各类别的预测情况 | 分析混淆情况 |

#### 2.3.2 数据划分

- **训练集**：80%（约475条）
- **测试集**：20%（约119条）
- 使用**分层采样**（stratified split）保持类别比例

### 2.4 持续学习机制

#### 2.4.1 反馈收集

系统通过`/feedback`接口收集用户反馈：
- 记录用户修正的标签
- 存储到SQLite数据库
- 用于后续模型迭代

#### 2.4.2 模型迭代流程

```
初始训练集（594条）
    ↓
训练模型 v1.0
    ↓
部署上线，收集反馈
    ↓
积累反馈数据
    ↓
合并训练集 + 反馈数据
    ↓
重新训练模型 v2.0
    ↓
评估对比，替换模型
```

**迭代建议**：
- 积累50-100条反馈后进行首次迭代
- 定期（如每周/每月）重新训练
- 保留模型版本，方便回滚

---

## 3. 使用指南

### 3.1 环境要求

- **Python版本**：3.8+
- **操作系统**：Windows 11 / Linux / macOS
- **依赖包**：见`pyproject.toml`

### 3.2 安装步骤

#### 步骤1：安装依赖

```bash
uv sync
```

#### 步骤2：准备数据

确保`issue_data.csv`文件存在，格式如下：

```csv
title,description,label
"System performance issue","CPU usage is high...",0
"Battery drains fast","Battery life is short...",1
...
```

### 3.3 训练模型

运行训练脚本：

```bash
uv run train_model.py
```

**训练过程**：
1. 加载数据集
2. 文本预处理（jieba分词）
3. 划分训练集和测试集
4. 对比多种算法
5. 训练最终模型
6. 评估模型性能
7. 生成混淆矩阵图
8. 保存模型文件

**输出文件**：
- `models/issue_classifier.pkl` - 训练好的分类器
- `models/tfidf_vectorizer.pkl` - TF-IDF向量化器
- `confusion_matrix.png` - 混淆矩阵可视化

**训练示例输出**：
```
============================================================
Issue场景分类模型训练
============================================================

正在加载数据...
数据集大小: (594, 3)

============================================================
数据准备阶段
============================================================
正在合并title和description字段...
正在进行文本预处理（jieba分词）...
数据样本数: 594
标签分布:
0    150
1    120
2     80
...

============================================================
模型训练阶段
============================================================
使用模型: 逻辑回归 (Logistic Regression)
正在训练模型...
模型训练完成！

============================================================
模型评估阶段
============================================================
测试集准确率: 0.8571
测试集F1分数: 0.8543

分类报告:
              precision    recall  f1-score   support
performance       0.85      0.89      0.87        30
...
```

### 3.4 启动Web服务

运行Web服务：

```bash
uv run app.py
```

服务启动后，访问：
- **主页**：http://localhost:8000
- **API文档**：http://localhost:8000/docs
- **健康检查**：http://localhost:8000/health

---

## 4. API接口说明

### 4.1 预测接口 - POST /predict

**功能**：根据Issue的标题和描述预测场景

**请求格式**：
```json
{
  "title": "System hang during stress test",
  "description": "The system becomes unresponsive when running CPU and GPU stress testing for more than 30 minutes."
}
```

**响应格式**：
```json
{
  "predicted_label": 4,
  "predicted_scene": "hang",
  "confidence": 0.8523,
  "all_probabilities": {
    "performance": 0.0521,
    "battery life": 0.0234,
    "单双烤": 0.0432,
    "BSOD": 0.0156,
    "hang": 0.8523,
    "abnormal reboot": 0.0089,
    "abnormal shutdown": 0.0045
  }
}
```

**字段说明**：
- `predicted_label`：预测的标签编号（0-6）
- `predicted_scene`：预测的场景名称
- `confidence`：预测置信度（0-1之间）
- `all_probabilities`：所有场景的概率分布

**使用示例**：

```python
import requests

url = "http://localhost:8000/predict"
data = {
    "title": "System hang during stress test",
    "description": "The system becomes unresponsive..."
}

response = requests.post(url, json=data)
result = response.json()

print(f"预测场景: {result['predicted_scene']}")
print(f"置信度: {result['confidence']:.2%}")
```

```bash
# 使用curl
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "System hang during stress test",
    "description": "The system becomes unresponsive..."
  }'
```

### 4.2 反馈接口 - POST /feedback

**功能**：提交用户修正的标签，用于模型持续学习

**请求格式**：
```json
{
  "title": "System hang during stress test",
  "description": "The system becomes unresponsive...",
  "predicted_label": 4,
  "correct_label": 2,
  "user_id": "user_123"
}
```

**响应格式**：
```json
{
  "success": true,
  "message": "感谢您的反馈！我们会学习这个案例（预测: hang → 正确: 单双烤）。",
  "feedback_id": 1
}
```

**字段说明**：
- `title`：Issue标题
- `description`：Issue描述
- `predicted_label`：系统预测的标签
- `correct_label`：用户修正后的正确标签
- `user_id`：用户ID（可选）

**使用示例**：

```python
import requests

url = "http://localhost:8000/feedback"
data = {
    "title": "System hang during stress test",
    "description": "The system becomes unresponsive...",
    "predicted_label": 4,
    "correct_label": 2,
    "user_id": "user_123"
}

response = requests.post(url, json=data)
result = response.json()

print(result['message'])
```

### 4.3 统计接口 - GET /stats

**功能**：查看反馈统计信息

**响应格式**：
```json
{
  "success": true,
  "data": {
    "total_feedback": 150,
    "incorrect_predictions": 23,
    "accuracy": 0.8467,
    "error_by_scene": {
      "performance": 5,
      "hang": 8,
      "单双烤": 10
    }
  },
  "timestamp": "2025-11-13T15:30:00"
}
```

### 4.4 反馈列表接口 - GET /feedback/list

**功能**：获取反馈记录列表

**请求参数**：
- `limit`：返回记录数量（默认100）

**响应格式**：
```json
{
  "success": true,
  "count": 100,
  "total": 150,
  "data": [
    {
      "id": 1,
      "title": "...",
      "description": "...",
      "predicted_label": 4,
      "predicted_scene": "hang",
      "correct_label": 2,
      "correct_scene": "单双烤",
      "user_id": "user_123",
      "created_at": "2025-11-13 15:30:00"
    }
  ]
}
```

### 4.5 标签映射接口 - GET /labels

**功能**：获取所有场景标签映射

**响应格式**：
```json
{
  "success": true,
  "labels": {
    "0": "performance",
    "1": "battery life",
    ...
  },
  "reverse_labels": {
    "performance": 0,
    "battery life": 1,
    ...
  }
}
```

---

## 5. 模型迭代指南

### 5.1 数据准备

从数据库导出反馈数据：

```python
import sqlite3
import pandas as pd

# 连接数据库
conn = sqlite3.connect('feedback.db')

# 查询反馈数据
query = """
SELECT title, description, correct_label as label
FROM feedback
"""
feedback_df = pd.read_csv(query)

# 加载原始训练数据
original_df = pd.read_csv('issue_data.csv')

# 合并数据
combined_df = pd.concat([original_df, feedback_df], ignore_index=True)

# 保存合并后的数据
combined_df.to_csv('issue_data_updated.csv', index=False)
```

### 5.2 重新训练

修改`train_model.py`中的数据路径，然后运行：

```bash
uv run train_model.py
```

### 5.3 模型对比

训练脚本会自动进行新旧模型对比：
- 对比准确率
- 对比F1分数
- 分析混淆矩阵变化

### 5.4 模型部署

如果新模型效果更好：
1. 备份旧模型：
   ```bash
   cp models/issue_classifier.pkl models/issue_classifier_v1.pkl
   ```

2. 新模型已自动保存到`models/`目录

3. 重启Web服务：
   ```bash
   # 停止旧服务
   # 启动新服务
   uv run app.py
   ```

---

## 6. 项目结构

```
project/
├── config.py                  # 配置文件
├── train_model.py             # 训练脚本
├── app.py                     # Web服务
├── pyproject.toml           # 依赖包
├── 算法说明文档.md            # 本文档
├── issue_data.csv             # 训练数据集
├── models/                    # 模型文件目录
│   ├── issue_classifier.pkl   # 分类器模型
│   └── tfidf_vectorizer.pkl   # TF-IDF向量化器
├── feedback.db                # 反馈数据库
└── confusion_matrix.png       # 混淆矩阵图
```

---

## 7. 技术栈

- **编程语言**：Python 3.8+
- **机器学习**：scikit-learn
- **文本处理**：
  - 英文分词：nltk（含停用词过滤）
  - 中文分词：jieba
- **Web框架**：FastAPI
- **数据处理**：pandas, numpy
- **数据可视化**：matplotlib, seaborn
- **数据库**：SQLite



